# ‚ö†Ô∏è ATEN√á√ÉO: Modelos Grandes no Git

## üö® Problema Potencial

Voc√™ tem **1.4GB de modelos** para fazer commit:
- `models/semantic_matcher_finetuned/` ‚Üí **1.1GB** (modelo principal)
- `models/resume_classifier/run-2025-11-18-balanced/` ‚Üí **255MB**
- `models/unsupervised_scorer.pkl` ‚Üí **3MB**
- `models/scoring_model.pkl` ‚Üí **3MB**

**GitHub tem limite de 100MB por arquivo** e **recomenda usar Git LFS para arquivos > 50MB**.

---

## üéØ Op√ß√µes Dispon√≠veis

### Op√ß√£o 1: Git LFS (Recomendado para Colabora√ß√£o) ‚≠ê

**Quando usar**: Se outras pessoas precisar√£o clonar o reposit√≥rio com os modelos.

**Vantagens**:
- ‚úÖ Modelos ficam no reposit√≥rio (versionados)
- ‚úÖ Git gerencia automaticamente
- ‚úÖ Clones s√£o mais r√°pidos (modelos baixados sob demanda)

**Como fazer**:
```bash
# 1. Instalar Git LFS (uma vez)
git lfs install

# 2. Rastrear arquivos grandes
git lfs track "*.safetensors"
git lfs track "*.pkl"
git lfs track "models/semantic_matcher_finetuned/tokenizer.json"

# 3. Adicionar .gitattributes (criado automaticamente)
git add .gitattributes

# 4. Adicionar tudo e commitar
git add .
git commit -m "feat: Complete ML pipeline with REST API

‚ú® Features:
- Semantic matching model (Pearson 0.956, MAE 0.02)
- Hybrid scoring system (ML + Rule-Based)
- FastAPI REST API with 8 production endpoints
- Complete documentation and tests

üßπ Cleanup: -1.8GB, -61 files
üéØ Models tracked with Git LFS (1.4GB)"

# 5. Push
git push origin main
```

**Custo**: GitHub LFS tem 1GB gr√°tis/m√™s de armazenamento e 1GB de bandwidth.

---

### Op√ß√£o 2: Ignorar Modelos (Recomendado para Solo) üîí

**Quando usar**: Se voc√™ √© o √∫nico desenvolvedor e quer reposit√≥rio leve.

**Vantagens**:
- ‚úÖ Reposit√≥rio pequeno (~50MB)
- ‚úÖ Push/pull r√°pidos
- ‚úÖ Sem custos de LFS
- ‚úÖ Modelos ficam locais

**Como fazer**:
```bash
# 1. Adicionar modelos ao .gitignore
echo "" >> .gitignore
echo "# Modelos grandes (manter localmente)" >> .gitignore
echo "models/semantic_matcher_finetuned/" >> .gitignore
echo "models/resume_classifier/run-2025-11-18-balanced/" >> .gitignore
echo "models/unsupervised_scorer.pkl" >> .gitignore
echo "models/scoring_model.pkl" >> .gitignore

# 2. Remover do staging (se j√° adicionou)
git rm --cached -r models/semantic_matcher_finetuned 2>$null
git rm --cached -r models/resume_classifier/run-2025-11-18-balanced 2>$null
git rm --cached models/unsupervised_scorer.pkl 2>$null
git rm --cached models/scoring_model.pkl 2>$null

# 3. Commit
git add .
git commit -m "feat: Complete ML pipeline with REST API

‚ú® Features:
- Semantic matching model (Pearson 0.956, MAE 0.02)
- Hybrid scoring system (ML + Rule-Based)
- FastAPI REST API with 8 production endpoints
- Complete documentation and tests

üßπ Cleanup: -1.8GB, -61 files
üìù Note: Models (1.4GB) stored locally/cloud, not in repo"

# 4. Push
git push origin main

# 5. Documentar onde est√£o os modelos
echo "Modelos armazenados localmente em: E:\PI6\P.I.6\models\" > MODELS_LOCATION.md
git add MODELS_LOCATION.md
git commit -m "docs: Add models location reference"
git push
```

**Nota**: Crie backup dos modelos em cloud storage (Google Drive, Dropbox, S3, etc.)

---

### Op√ß√£o 3: Cloud Storage + Download Script üåê

**Quando usar**: Para produ√ß√£o ou equipes grandes.

**Vantagens**:
- ‚úÖ Reposit√≥rio leve
- ‚úÖ Modelos em infraestrutura escal√°vel
- ‚úÖ F√°cil distribui√ß√£o
- ‚úÖ Versionamento separado

**Como fazer**:

#### 1. Fazer Upload dos Modelos
```bash
# AWS S3 (exemplo)
aws s3 sync models/ s3://resumai-models/

# Google Cloud Storage (exemplo)
gsutil -m cp -r models/ gs://resumai-models/

# Azure Blob Storage (exemplo)
az storage blob upload-batch -d resumai-models -s models/
```

#### 2. Criar Script de Download
```python
# download_models.py
import requests
import os
from pathlib import Path

MODEL_URLS = {
    "semantic_matcher": "https://storage.example.com/semantic_matcher.tar.gz",
    "resume_classifier": "https://storage.example.com/resume_classifier.tar.gz",
    "unsupervised_scorer": "https://storage.example.com/unsupervised_scorer.pkl",
}

def download_models():
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    for name, url in MODEL_URLS.items():
        print(f"Downloading {name}...")
        # Download logic here
        
if __name__ == "__main__":
    download_models()
```

#### 3. Adicionar ao .gitignore e documentar
```bash
# Ignorar modelos
echo "models/*.safetensors" >> .gitignore
echo "models/semantic_matcher_finetuned/" >> .gitignore
echo "models/resume_classifier/run-*/" >> .gitignore

# Commit script
git add download_models.py
git add README.md  # Adicionar instru√ß√µes de download
git commit -m "feat: Add models download script"
git push
```

---

## üìä Compara√ß√£o das Op√ß√µes

| Crit√©rio | Git LFS | Ignorar | Cloud Storage |
|----------|---------|---------|---------------|
| **Tamanho do repo** | M√©dio (LFS pointers) | Pequeno | Pequeno |
| **Facilidade setup** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| **Colabora√ß√£o** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Custo** | $5/m√™s (50GB) | Gr√°tis | Vari√°vel |
| **Versionamento** | ‚úÖ | ‚ùå | ‚úÖ (manual) |
| **Performance** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üéØ Recomenda√ß√£o Final

### Para este projeto:

**RECOMENDO: Op√ß√£o 2 (Ignorar Modelos)** porque:
1. ‚úÖ Voc√™ √© desenvolvedor solo (n√£o precisa de LFS)
2. ‚úÖ Modelos foram treinados localmente
3. ‚úÖ Push/pull muito mais r√°pidos
4. ‚úÖ Sem custos adicionais
5. ‚úÖ Reposit√≥rio fica leve e profissional

**Backup dos Modelos**:
```bash
# Criar backup compactado
Compress-Archive -Path models/ -DestinationPath backup_models.zip

# Upload para Google Drive / Dropbox / OneDrive
# Ou guardar em HD externo
```

---

## üöÄ Comando Recomendado

Execute este comando para ignorar os modelos grandes:

```bash
# Adicionar ao .gitignore
echo "`n# Modelos grandes (manter localmente)" >> .gitignore
echo "models/semantic_matcher_finetuned/" >> .gitignore
echo "models/resume_classifier/run-2025-11-18-balanced/" >> .gitignore
echo "models/unsupervised_scorer.pkl" >> .gitignore
echo "models/scoring_model.pkl" >> .gitignore

# Commit e push
git add .gitignore
git commit -m "chore: Ignore large ML models (1.4GB)"
git add .
git commit -m "feat: Complete ML pipeline with REST API

‚ú® Features:
- Semantic matching model (Pearson 0.956, MAE 0.02)
- Hybrid scoring system (ML + Rule-Based)
- FastAPI REST API with 8 production endpoints
- Complete documentation and tests

üßπ Cleanup: -1.8GB, -61 files"

git push origin main
```

**Tamanho final do push**: ~50MB (c√≥digo + docs + imagens)

---

## ‚ùì FAQ

**Q: E se eu quiser compartilhar os modelos depois?**  
A: Upload para Google Drive e compartilhe o link no README.

**Q: Os modelos s√£o reproduz√≠veis?**  
A: Sim! Os scripts de treinamento est√£o no repo. Qualquer um pode treinar novamente.

**Q: Preciso versionar os modelos?**  
A: N√£o necessariamente. Se treinar novo modelo, pode sobrescrever ou criar nova pasta.

**Q: E se eu mudar de ideia?**  
A: Pode adicionar Git LFS depois facilmente.

---

## ‚úÖ Decis√£o

**Escolha uma op√ß√£o acima e execute os comandos correspondentes.**

Recomendo **Op√ß√£o 2** para este projeto! üéØ
