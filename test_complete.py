#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script de Teste Completo do ResumAI
Avalia a QUALIDADE de um currÃ­culo (sem necessidade de vaga)
"""
import sys
from pathlib import Path
from typing import Dict, Any

# Adicionar root ao path
sys.path.insert(0, str(Path(__file__).parent))

from app.scoring.hybrid_scorer import HybridScorer
from app.scoring.use_case import build_features_from_doc, build_subscores


def print_header(title: str):
    """Imprime cabeÃ§alho formatado"""
    print(f"\n{'='*70}")
    print(f"  {title}")
    print(f"{'='*70}")


def print_section(title: str):
    """Imprime seÃ§Ã£o formatada"""
    print(f"\n{'â”€'*70}")
    print(f"  {title}")
    print(f"{'â”€'*70}")


def format_score(score: float, max_val: float = 1.0) -> str:
    """Formata score com barra de progresso"""
    if max_val == 1.0:
        percentage = score * 100
        bar_length = int(score * 20)
    else:
        percentage = (score / max_val) * 100
        bar_length = int((score / max_val) * 20)
    
    bar = 'â–ˆ' * bar_length + 'â–‘' * (20 - bar_length)
    return f"{bar} {percentage:.1f}%"


def test_complete_pipeline(resume_path: str):
    """
    Testa pipeline completo do ResumAI - AvaliaÃ§Ã£o de Qualidade
    
    Args:
        resume_path: Caminho para arquivo .txt do currÃ­culo
    """
    
    print_header("ğŸ§ª AVALIAÃ‡ÃƒO DE QUALIDADE - ResumAI")
    print(f"ğŸ“„ CurrÃ­culo: {resume_path}")
    
    # 1. Carregar currÃ­culo
    print_section("1ï¸âƒ£ Carregando CurrÃ­culo")
    try:
        with open(resume_path, 'r', encoding='utf-8') as f:
            resume_text = f.read()
        
        print(f"âœ… Arquivo carregado: {len(resume_text)} caracteres")
        print(f"ğŸ“ Preview (primeiros 200 chars):")
        print(f"   {resume_text[:200]}...")
    except Exception as e:
        print(f"âŒ Erro ao carregar arquivo: {e}")
        return
    
    # Preparar documento (sem vaga - foco em qualidade)
    doc = {
        "resume_text_clean": resume_text,
        "job_description": None
    }
    
    # 2. ExtraÃ§Ã£o de Features
    print_section("2ï¸âƒ£ ExtraÃ§Ã£o de Features (NLP + Regex)")
    try:
        features = build_features_from_doc(doc)
        
        # Adicionar has_experience ao doc para o hybrid_scorer usar
        doc['has_experience'] = features.get('has_experience', False)
        
        print(f"\nğŸ“Š Features ExtraÃ­das:")
        print(f"   ğŸ”§ Skills detectadas: {len(features.get('skills', []))}")
        if features.get('skills'):
            print(f"      â†’ {', '.join(features['skills'][:10])}")
            if len(features['skills']) > 10:
                print(f"      ... e mais {len(features['skills']) - 10}")
        
        print(f"\n   ğŸ“… ExperiÃªncia:")
        print(f"      â†’ Anos de experiÃªncia: {features.get('years_total', 0):.1f} anos")
        print(f"      â†’ Tem experiÃªncia: {'âœ…' if features.get('has_experience') else 'âŒ'}")
        
        print(f"\n   ğŸ“ˆ ConteÃºdo:")
        print(f"      â†’ MÃ©tricas quantificÃ¡veis: {features.get('metrics_hits', 0)}")
        print(f"      â†’ Projetos mencionados: {features.get('project_hits', 0)}")
        print(f"      â†’ CertificaÃ§Ãµes: {features.get('cert_points', 0)}")
        
        print(f"\n   ğŸ“ Qualidade do Documento:")
        print(f"      â†’ Tokens: {features.get('tokens', 0)}")
        print(f"      â†’ SeÃ§Ãµes presentes: {features.get('sections_present', 0)}")
        print(f"      â†’ Tem email: {'âœ…' if features.get('has_email') else 'âŒ'}")
        print(f"      â†’ Tem telefone: {'âœ…' if features.get('has_phone') else 'âŒ'}")
        
    except Exception as e:
        print(f"âŒ Erro na extraÃ§Ã£o de features: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 3. ClassificaÃ§Ã£o de ExperiÃªncia
    print_section("3ï¸âƒ£ ClassificaÃ§Ã£o de ExperiÃªncia (BERT)")
    try:
        scorer = HybridScorer()
        result = scorer.score(doc)
        
        # Usar has_experience das features (mais confiÃ¡vel)
        is_experienced = features.get('has_experience', False)
        confidence = result.get('ml_confidence', 0)
        
        print(f"\nğŸ¯ Resultado:")
        print(f"   ClassificaÃ§Ã£o: {'âœ… EXPERIENTE' if is_experienced else 'âŒ SEM EXPERIÃŠNCIA'}")
        print(f"   ConfianÃ§a do modelo: {format_score(confidence)}")
        print(f"   MÃ©todo usado: {result.get('method', 'unknown').upper()}")
        
    except Exception as e:
        print(f"âŒ Erro na classificaÃ§Ã£o: {e}")
        import traceback
        traceback.print_exc()
    
    # 4. Scoring HÃ­brido (ML + Rule-Based)
    print_section("4ï¸âƒ£ Scoring HÃ­brido (ML + Rule-Based)")
    try:
        subscores = result.get('rb_subscores', {})
        final_score = result.get('score', 0)
        label = result.get('label', 'Desconhecido')
        
        print(f"\nğŸ“Š AvaliaÃ§Ã£o por Categoria:")
        subscore_names = {
            'skills': 'ğŸ”§ Habilidades TÃ©cnicas',
            'experience': 'ğŸ“… ExperiÃªncia',
            'projects': 'ğŸš€ Projetos',
            'certs': 'ğŸ“ CertificaÃ§Ãµes',
            'impact': 'ğŸ“ˆ Resultados/MÃ©tricas',
            'doc_quality': 'ğŸ“ Qualidade do Documento',
            'contact': 'ğŸ“ InformaÃ§Ãµes de Contato'
        }
        
        # Mostrar apenas scores relevantes (sem semantic e context que eram para matching)
        for key, name in subscore_names.items():
            if key in subscores:
                score = subscores[key]
                print(f"   {name}: {format_score(score)}")
        
        print(f"\nğŸ¯ AvaliaÃ§Ã£o Final:")
        print(f"   {format_score(final_score, 100)} ({final_score:.1f}/100)")
        print(f"   Qualidade: {label.upper()}")
        
        # ExplicaÃ§Ã£o
        explain = result.get('explain', {})
        if explain.get('top_up'):
            top_up_filtered = [s for s in explain['top_up'] if s not in ['semantic', 'context']]
            if top_up_filtered:
                print(f"\n   â¬†ï¸  Pontos fortes: {', '.join(top_up_filtered[:3])}")
        if explain.get('top_down'):
            top_down_filtered = [s for s in explain['top_down'] if s not in ['semantic', 'context']]
            if top_down_filtered:
                print(f"   â¬‡ï¸  Pontos a melhorar: {', '.join(top_down_filtered[:3])}")
        
    except Exception as e:
        print(f"âŒ Erro no scoring: {e}")
        import traceback
        traceback.print_exc()
    
    # 5. Resumo Final
    print_header("ğŸ“‹ RESUMO FINAL")
    
    print(f"\nâœ… AvaliaÃ§Ã£o ConcluÃ­da!")
    print(f"\nğŸ“Š Resumo:")
    print(f"   â€¢ Skills identificadas: {len(features.get('skills', []))}")
    print(f"   â€¢ Perfil: {'Experiente' if is_experienced else 'EstagiÃ¡rio/JÃºnior'}")
    print(f"   â€¢ Score: {final_score:.1f}/100")
    print(f"   â€¢ AvaliaÃ§Ã£o: {label.upper()}")
    print(f"   â€¢ SeÃ§Ãµes do currÃ­culo: {features.get('sections_present', 0)}")
    
    # CritÃ©rio usado
    cutoff = 50.0 if is_experienced else 40.0
    perfil_nome = "Experiente" if is_experienced else "EstagiÃ¡rio/JÃºnior"
    print(f"\nğŸ“Œ CritÃ©rio aplicado: {perfil_nome} (>= {cutoff:.0f} = BOM)")
    
    print(f"\nğŸ’¡ RecomendaÃ§Ãµes para Melhoria:")
    recommendations = []
    
    if subscores.get('skills', 0) < 0.6:
        recommendations.append("   â€¢ Adicionar mais habilidades tÃ©cnicas relevantes")
    if subscores.get('experience', 0) < 0.5:
        recommendations.append("   â€¢ Detalhar melhor a experiÃªncia profissional com perÃ­odos e responsabilidades")
    if subscores.get('projects', 0) < 0.5:
        recommendations.append("   â€¢ Incluir projetos relevantes (acadÃªmicos, pessoais ou profissionais)")
    if subscores.get('impact', 0) < 0.6:
        recommendations.append("   â€¢ Quantificar resultados e impacto (nÃºmeros, mÃ©tricas, percentuais)")
    if subscores.get('doc_quality', 0) < 0.7:
        recommendations.append("   â€¢ Melhorar estrutura: adicionar seÃ§Ãµes importantes (FormaÃ§Ã£o, Projetos, etc.)")
    if not features.get('has_email') or not features.get('has_phone'):
        recommendations.append("   â€¢ Garantir que email e telefone estejam visÃ­veis")
    if subscores.get('certs', 0) < 0.5:
        recommendations.append("   â€¢ Adicionar certificaÃ§Ãµes e cursos relevantes")
    
    if recommendations:
        for rec in recommendations[:5]:  # Mostrar no mÃ¡ximo 5 recomendaÃ§Ãµes
            print(rec)
    else:
        print("   âœ… CurrÃ­culo estÃ¡ bem estruturado!")
    
    print(f"\nğŸ¯ Resultado Final:")
    if label == "Bom":
        print(f"   âœ… BOM - CurrÃ­culo tem boa qualidade")
        print(f"      EstÃ¡ aprovado para seguir no processo de avaliaÃ§Ã£o!")
    else:
        print(f"   âŒ RUIM - CurrÃ­culo precisa de melhorias")
        print(f"      Recomenda-se revisÃ£o antes de submeter para processos seletivos.")
    
    print(f"\n{'='*70}\n")


def main():
    """FunÃ§Ã£o principal"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="AvaliaÃ§Ã£o de Qualidade de CurrÃ­culo - ResumAI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:

  # Avaliar qualidade de um currÃ­culo
  python test_complete.py curriculo.txt
  
  # Avaliar currÃ­culo com caminho especÃ­fico
  python test_complete.py "C:\\Users\\Nome\\Desktop\\meu_curriculo.txt"
        """
    )
    
    parser.add_argument('resume', help='Caminho para arquivo .txt do currÃ­culo')
    
    args = parser.parse_args()
    
    # Executar avaliaÃ§Ã£o
    test_complete_pipeline(args.resume)


if __name__ == "__main__":
    main()
